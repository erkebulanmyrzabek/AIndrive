#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å Kaggle
–ê–≤—Ç–æ—Ä: AI Assistant
"""

import os
import shutil
import yaml
from pathlib import Path
import random
import kagglehub

def download_car_damage_dataset():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç car-damage-detection —Å Kaggle"""
    print("üì• –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç car-damage-detection —Å Kaggle...")
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        path = kagglehub.dataset_download("anujms/car-damage-detection")
        print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–∫–∞—á–∞–Ω –≤: {path}")
        return path
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {e}")
        print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω kagglehub: pip install kagglehub")
        return None

def prepare_dataset_structure():
    """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è YOLO –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("üìÅ –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    directories = [
        "dataset",
        "dataset/images",
        "dataset/images/train",
        "dataset/images/val", 
        "dataset/images/test",
        "dataset/labels",
        "dataset/labels/train",
        "dataset/labels/val",
        "dataset/labels/test",
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"   ‚úÖ {directory}/")

def convert_dataset_to_yolo(kaggle_path, output_path="dataset"):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–∫–∞—á–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç YOLO"""
    print(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç YOLO...")
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    prepare_dataset_structure()
    
    # –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤ (–∞–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–¥ –Ω–∞—à —Ñ–æ—Ä–º–∞—Ç)
    class_mapping = {
        'dent': 2,      # dented
        'scratch': 3,   # scratched  
        'dirty': 1,     # dirty
        'clean': 0,     # clean
        'broken': 4,    # broken
        'damage': 4,    # broken (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)
    }
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
    image_files = []
    
    for ext in image_extensions:
        image_files.extend(Path(kaggle_path).glob(f"**/*{ext}"))
        image_files.extend(Path(kaggle_path).glob(f"**/*{ext.upper()}"))
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}")
    
    if len(image_files) == 0:
        print("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Å–∫–∞—á–∞–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ!")
        return False
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val/test (80/10/10)
    random.shuffle(image_files)
    train_split = int(0.8 * len(image_files))
    val_split = int(0.9 * len(image_files))
    
    train_files = image_files[:train_split]
    val_files = image_files[train_split:val_split]
    test_files = image_files[val_split:]
    
    print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: train={len(train_files)}, val={len(val_files)}, test={len(test_files)}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
    for i, files in enumerate([train_files, val_files, test_files]):
        split_name = ['train', 'val', 'test'][i]
        
        for img_file in files:
            try:
                # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                dest_img = f"{output_path}/images/{split_name}/{img_file.name}"
                shutil.copy2(img_file, dest_img)
                
                # –ò—â–µ–º —Ñ–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
                label_file = img_file.with_suffix('.txt')
                if not label_file.exists():
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
                    for subdir in ['labels', 'annotations', 'yolo']:
                        potential_label = img_file.parent / subdir / f"{img_file.stem}.txt"
                        if potential_label.exists():
                            label_file = potential_label
                            break
                
                # –°–æ–∑–¥–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
                dest_label = f"{output_path}/labels/{split_name}/{img_file.stem}.txt"
                if label_file.exists():
                    convert_annotation_file(label_file, dest_label, class_mapping)
                else:
                    # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
                    with open(dest_label, "w") as f:
                        f.write("")
                        
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {img_file}: {e}")
    
    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ {output_path}/")
    return True

def convert_annotation_file(input_file, output_file, class_mapping):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç YOLO"""
    try:
        with open(input_file, 'r') as f:
            lines = f.readlines()
        
        converted_lines = []
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            parts = line.split()
            if len(parts) >= 5:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç —á–∏—Å–ª–æ–º (—É–∂–µ YOLO —Ñ–æ—Ä–º–∞—Ç)
                try:
                    int(parts[0])
                    # –£–∂–µ –≤ YOLO —Ñ–æ—Ä–º–∞—Ç–µ
                    converted_lines.append(line)
                except ValueError:
                    # –ù—É–∂–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
                    class_name = parts[0].lower()
                    if class_name in class_mapping:
                        class_id = class_mapping[class_name]
                        converted_line = f"{class_id} {' '.join(parts[1:])}"
                        converted_lines.append(converted_line)
            else:
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–ª–∞—Å—Å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                line_lower = line.lower()
                for class_name, class_id in class_mapping.items():
                    if class_name in line_lower:
                        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
                        converted_line = f"{class_id} 0.5 0.5 0.1 0.1"
                        converted_lines.append(converted_line)
                        break
        
        with open(output_file, 'w') as f:
            f.write('\n'.join(converted_lines))
            
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ {input_file}: {e}")
        # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
        with open(output_file, 'w') as f:
            f.write("")

def create_sample_annotations():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üìù –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π...")
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
    from create_test_image import create_test_car_image, create_clean_car_image
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    create_test_car_image("dataset/images/train/car_damaged_1.jpg")
    create_clean_car_image("dataset/images/train/car_clean_1.jpg")
    create_test_car_image("dataset/images/val/car_damaged_val.jpg")
    create_clean_car_image("dataset/images/test/car_clean_test.jpg")
    
    # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
    damaged_annotations = [
        "1 0.3 0.4 0.1 0.1",  # dirty
        "3 0.2 0.3 0.15 0.05",  # scratch
        "2 0.1 0.5 0.08 0.12",  # dent
        "4 0.4 0.2 0.1 0.08",  # broken
    ]
    
    # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
    clean_annotations = [
        "0 0.5 0.5 0.8 0.6",  # clean
    ]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    with open("dataset/labels/train/car_damaged_1.txt", "w") as f:
        f.write("\n".join(damaged_annotations))
    
    with open("dataset/labels/train/car_clean_1.txt", "w") as f:
        f.write(clean_annotations[0])
    
    with open("dataset/labels/val/car_damaged_val.txt", "w") as f:
        f.write("\n".join(damaged_annotations))
    
    with open("dataset/labels/test/car_clean_test.txt", "w") as f:
        f.write(clean_annotations[0])

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("üì• –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê –° KAGGLE")
    print("=" * 60)
    
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç:")
    print("1. –°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å")
    print("2. –°–æ–∑–¥–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ (–±—ã—Å—Ç—Ä–æ)")
    print("3. –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏")
    
    choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-3): ").strip()
    
    if choice == "1":
        # –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        kaggle_path = download_car_damage_dataset()
        if kaggle_path:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
            if convert_dataset_to_yolo(kaggle_path):
                print("\nüéâ –î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤! –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å: python train_yolo.py")
            else:
                print("\n‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏. –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞...")
                create_sample_annotations()
                print("‚úÖ –ü—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–æ–∑–¥–∞–Ω!")
    
    elif choice == "2":
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
        prepare_dataset_structure()
        create_sample_annotations()
        print("‚úÖ –ü—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–æ–∑–¥–∞–Ω!")
        print("   –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å: python train_yolo.py")
    
    elif choice == "3":
        show_instructions()
    
    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä!")

def show_instructions():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"""
    print("\n" + "="*60)
    print("üìã –ò–ù–°–¢–†–£–ö–¶–ò–ò")
    print("="*60)
    
    print("\nüîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ kagglehub:")
    print("pip install kagglehub")
    
    print("\nüì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    print("python download_kaggle_dataset.py")
    print("–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç 1")
    
    print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏:")
    print("python train_yolo.py")
    
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:")
    print("python detect.py")

if __name__ == "__main__":
    main()
