#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ONNX –º–æ–¥–µ–ª–∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
–ê–≤—Ç–æ—Ä: AI Assistant
"""

import os
import cv2
import numpy as np
import onnxruntime as ort
from PIL import Image
import torch

class YOLOv8ONNXInference:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ YOLOv8 ONNX –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, onnx_path, conf_threshold=0.5, iou_threshold=0.45):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ONNX –º–æ–¥–µ–ª–∏
        
        Args:
            onnx_path: –ø—É—Ç—å –∫ ONNX —Ñ–∞–π–ª—É
            conf_threshold: –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            iou_threshold: –ø–æ—Ä–æ–≥ IoU –¥–ª—è NMS
        """
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º ONNX –º–æ–¥–µ–ª—å
        providers = ['CPUExecutionProvider']
        if torch.cuda.is_available():
            providers.insert(0, 'CUDAExecutionProvider')
        
        self.session = ort.InferenceSession(onnx_path, providers=providers)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ö–æ–¥–µ –∏ –≤—ã—Ö–æ–¥–µ
        self.input_name = self.session.get_inputs()[0].name
        self.input_shape = self.session.get_inputs()[0].shape
        self.output_names = [output.name for output in self.session.get_outputs()]
        
        print(f"‚úÖ ONNX –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {onnx_path}")
        print(f"   –í—Ö–æ–¥: {self.input_name}, —Ñ–æ—Ä–º–∞: {self.input_shape}")
        print(f"   –í—ã—Ö–æ–¥—ã: {self.output_names}")
        print(f"   –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã: {self.session.get_providers()}")
        
        # –ö–ª–∞—Å—Å—ã
        self.class_names = ['clean', 'dirty', 'dented', 'scratched', 'broken']
        self.class_colors = [
            (0, 255, 0),      # clean - –∑–µ–ª–µ–Ω—ã–π
            (0, 165, 255),    # dirty - –æ—Ä–∞–Ω–∂–µ–≤—ã–π
            (0, 0, 255),      # dented - –∫—Ä–∞—Å–Ω—ã–π
            (255, 0, 0),      # scratched - —Å–∏–Ω–∏–π
            (128, 0, 128),    # broken - —Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π
        ]
    
    def preprocess_image(self, image_path, target_size=640):
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è YOLOv8
        
        Args:
            image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            target_size: —Ä–∞–∑–º–µ—Ä –¥–ª—è —Ä–µ—Å–∞–π–∑–∞
            
        Returns:
            preprocessed_image: –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            original_image: –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            scale_factor: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        
        original_image = image.copy()
        h, w = image.shape[:2]
        
        # –†–µ—Å–∞–π–∑ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
        scale = min(target_size / h, target_size / w)
        new_h, new_w = int(h * scale), int(w * scale)
        
        image = cv2.resize(image, (new_w, new_h))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥ –¥–æ target_size x target_size
        pad_h = target_size - new_h
        pad_w = target_size - new_w
        
        image = cv2.copyMakeBorder(
            image, 0, pad_h, 0, pad_w,
            cv2.BORDER_CONSTANT, value=(114, 114, 114)
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ –∫–∞–Ω–∞–ª–æ–≤
        image = image.astype(np.float32) / 255.0
        image = np.transpose(image, (2, 0, 1))  # HWC -> CHW
        image = np.expand_dims(image, axis=0)   # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
        
        return image, original_image, scale
    
    def postprocess_outputs(self, outputs, scale_factor, original_shape):
        """
        –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏
        
        Args:
            outputs: –≤—ã—Ö–æ–¥—ã ONNX –º–æ–¥–µ–ª–∏
            scale_factor: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
            original_shape: —Ñ–æ—Ä–º–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Returns:
            boxes: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox
            scores: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            class_ids: ID –∫–ª–∞—Å—Å–æ–≤
        """
        # YOLOv8 –≤—ã–¥–∞–µ—Ç –æ–¥–∏–Ω –≤—ã—Ö–æ–¥ —Å —Ñ–æ—Ä–º–æ–π [1, 84, 8400]
        # –≥–¥–µ 84 = 4 (bbox) + 80 (–∫–ª–∞—Å—Å—ã COCO) - –Ω–æ —É –Ω–∞—Å 5 –∫–ª–∞—Å—Å–æ–≤
        predictions = outputs[0]  # [1, 84, 8400]
        predictions = np.transpose(predictions, (0, 2, 1))  # [1, 8400, 84]
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º bbox –∏ scores
        boxes = predictions[0, :, :4]  # [8400, 4] - x_center, y_center, width, height
        scores = predictions[0, :, 4:]  # [8400, 80] - scores –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        max_scores = np.max(scores, axis=1)
        valid_indices = max_scores > self.conf_threshold
        
        if not np.any(valid_indices):
            return np.array([]), np.array([]), np.array([])
        
        boxes = boxes[valid_indices]
        scores = scores[valid_indices]
        max_scores = max_scores[valid_indices]
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å—ã
        class_ids = np.argmax(scores, axis=1)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ YOLO —Ñ–æ—Ä–º–∞—Ç–∞ –≤ –æ–±—ã—á–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        x_center, y_center, width, height = boxes.T
        
        x1 = (x_center - width / 2) / scale_factor
        y1 = (y_center - height / 2) / scale_factor
        x2 = (x_center + width / 2) / scale_factor
        y2 = (y_center + height / 2) / scale_factor
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ä–∞–∑–º–µ—Ä–∞–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        h, w = original_shape[:2]
        x1 = np.clip(x1, 0, w)
        y1 = np.clip(y1, 0, h)
        x2 = np.clip(x2, 0, w)
        y2 = np.clip(y2, 0, h)
        
        boxes = np.column_stack([x1, y1, x2, y2])
        
        return boxes, max_scores, class_ids
    
    def draw_detections(self, image, boxes, scores, class_ids):
        """–û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
        img_with_detections = image.copy()
        
        for box, score, class_id in zip(boxes, scores, class_ids):
            x1, y1, x2, y2 = map(int, box)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ü–≤–µ—Ç –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
            color = self.class_colors[class_id % len(self.class_colors)]
            class_name = self.class_names[class_id] if class_id < len(self.class_names) else f'class_{class_id}'
            
            # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            cv2.rectangle(img_with_detections, (x1, y1), (x2, y2), color, 2)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
            label = f'{class_name}: {score:.2f}'
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
            )
            
            # –†–∏—Å—É–µ–º —Ñ–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            cv2.rectangle(
                img_with_detections,
                (x1, y1 - text_height - baseline),
                (x1 + text_width, y1),
                color,
                -1
            )
            
            # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç
            cv2.putText(
                img_with_detections,
                label,
                (x1, y1 - baseline),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                2
            )
        
        return img_with_detections
    
    def predict(self, image_path, output_path=None):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        
        Args:
            image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            
        Returns:
            boxes, scores, class_ids: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏
        """
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        input_image, original_image, scale = self.preprocess_image(image_path)
        
        # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
        outputs = self.session.run(self.output_names, {self.input_name: input_image})
        
        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
        boxes, scores, class_ids = self.postprocess_outputs(
            outputs, scale, original_image.shape
        )
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ –¥–µ—Ç–µ–∫—Ü–∏–π: {len(boxes)}")
        for i, (box, score, class_id) in enumerate(zip(boxes, scores, class_ids)):
            class_name = self.class_names[class_id] if class_id < len(self.class_names) else f'class_{class_id}'
            print(f"   {i+1}. {class_name}: {score:.3f}")
        
        # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏
        if len(boxes) > 0:
            img_with_detections = self.draw_detections(original_image, boxes, scores, class_ids)
            
            if output_path:
                cv2.imwrite(output_path, img_with_detections)
                print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        
        return boxes, scores, class_ids

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("üöÄ –ò–ù–§–ï–†–ï–ù–° –° ONNX –ú–û–î–ï–õ–¨–Æ YOLOv8")
    print("=" * 60)
    
    # –ü—É—Ç—å –∫ ONNX –º–æ–¥–µ–ª–∏
    onnx_path = "exports/best.onnx"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    if not os.path.exists(onnx_path):
        print(f"‚ùå ONNX –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {onnx_path}")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ export_onnx.py –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –º–æ–¥–µ–ª–∏")
        return
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –æ–±—ä–µ–∫—Ç
    try:
        inference = YOLOv8ONNXInference(onnx_path, conf_threshold=0.5)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ ONNX –º–æ–¥–µ–ª–∏: {e}")
        return
    
    # –¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    test_image = "test_images/car1.jpg"
    
    if os.path.exists(test_image):
        print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏: {test_image}")
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        os.makedirs("onnx_results", exist_ok=True)
        output_path = "onnx_results/onnx_detection.jpg"
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        boxes, scores, class_ids = inference.predict(test_image, output_path)
        
        print(f"\n‚úÖ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
    else:
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {test_image}")
        print("   –°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é test_images/ –∏ –ø–æ–º–µ—Å—Ç–∏—Ç–µ —Ç—É–¥–∞ car1.jpg")

if __name__ == "__main__":
    main()
