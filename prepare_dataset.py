#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
–ê–≤—Ç–æ—Ä: AI Assistant
"""

import os
import shutil
import yaml
from pathlib import Path
import random

def create_sample_dataset():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üé® –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    from create_test_image import create_test_car_image, create_clean_car_image
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    create_test_car_image("dataset/images/train/car_damaged_1.jpg")
    create_clean_car_image("dataset/images/train/car_clean_1.jpg")
    create_test_car_image("dataset/images/train/car_damaged_2.jpg")
    create_clean_car_image("dataset/images/train/car_clean_2.jpg")
    
    # –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    create_test_car_image("dataset/images/val/car_damaged_val_1.jpg")
    create_clean_car_image("dataset/images/val/car_clean_val_1.jpg")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    create_test_car_image("dataset/images/test/car_damaged_test_1.jpg")
    create_clean_car_image("dataset/images/test/car_clean_test_1.jpg")
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ (–ø—Ä–∏–º–µ—Ä—ã)
    create_sample_annotations()
    
    print("‚úÖ –ü—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–æ–∑–¥–∞–Ω!")

def create_sample_annotations():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    
    # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
    damaged_annotations = [
        "1 0.3 0.4 0.1 0.1",  # dirty spot
        "3 0.2 0.3 0.15 0.05",  # scratch
        "2 0.1 0.5 0.08 0.12",  # dent
        "4 0.4 0.2 0.1 0.08",  # broken glass
    ]
    
    # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è
    clean_annotations = [
        "0 0.5 0.5 0.8 0.6",  # clean car
    ]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    with open("dataset/labels/train/car_damaged_1.txt", "w") as f:
        f.write("\n".join(damaged_annotations))
    
    with open("dataset/labels/train/car_clean_1.txt", "w") as f:
        f.write(clean_annotations[0])
    
    with open("dataset/labels/train/car_damaged_2.txt", "w") as f:
        f.write("\n".join(damaged_annotations))
    
    with open("dataset/labels/train/car_clean_2.txt", "w") as f:
        f.write(clean_annotations[0])
    
    # –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    with open("dataset/labels/val/car_damaged_val_1.txt", "w") as f:
        f.write("\n".join(damaged_annotations))
    
    with open("dataset/labels/val/car_clean_val_1.txt", "w") as f:
        f.write(clean_annotations[0])
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    with open("dataset/labels/test/car_damaged_test_1.txt", "w") as f:
        f.write("\n".join(damaged_annotations))
    
    with open("dataset/labels/test/car_clean_test_1.txt", "w") as f:
        f.write(clean_annotations[0])

def convert_kaggle_dataset(kaggle_path, output_path="dataset"):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle –≤ —Ñ–æ—Ä–º–∞—Ç YOLO"""
    print(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ {kaggle_path}...")
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    os.makedirs(f"{output_path}/images/train", exist_ok=True)
    os.makedirs(f"{output_path}/images/val", exist_ok=True)
    os.makedirs(f"{output_path}/images/test", exist_ok=True)
    os.makedirs(f"{output_path}/labels/train", exist_ok=True)
    os.makedirs(f"{output_path}/labels/val", exist_ok=True)
    os.makedirs(f"{output_path}/labels/test", exist_ok=True)
    
    # –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤ (–∞–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –ø–æ–¥ –≤–∞—à –¥–∞—Ç–∞—Å–µ—Ç)
    class_mapping = {
        'dent': 2,      # dented
        'scratch': 3,   # scratched
        'dirty': 1,     # dirty
        'clean': 0,     # clean
        'broken': 4,    # broken
    }
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image_files = list(Path(kaggle_path).glob("**/*.jpg")) + list(Path(kaggle_path).glob("**/*.png"))
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val/test (80/10/10)
    random.shuffle(image_files)
    train_split = int(0.8 * len(image_files))
    val_split = int(0.9 * len(image_files))
    
    train_files = image_files[:train_split]
    val_files = image_files[train_split:val_split]
    test_files = image_files[val_split:]
    
    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
    for i, files in enumerate([train_files, val_files, test_files]):
        split_name = ['train', 'val', 'test'][i]
        
        for img_file in files:
            # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            shutil.copy2(img_file, f"{output_path}/images/{split_name}/")
            
            # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
            label_file = img_file.with_suffix('.txt')
            if label_file.exists():
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                convert_annotation_file(label_file, f"{output_path}/labels/{split_name}/{img_file.name}.txt", class_mapping)
            else:
                # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
                with open(f"{output_path}/labels/{split_name}/{img_file.name}.txt", "w") as f:
                    f.write("")
    
    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ {output_path}/")

def convert_annotation_file(input_file, output_file, class_mapping):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç YOLO"""
    try:
        with open(input_file, 'r') as f:
            lines = f.readlines()
        
        converted_lines = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) >= 5:
                class_name = parts[0]
                if class_name in class_mapping:
                    class_id = class_mapping[class_name]
                    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    converted_line = f"{class_id} {' '.join(parts[1:])}"
                    converted_lines.append(converted_line)
        
        with open(output_file, 'w') as f:
            f.write('\n'.join(converted_lines))
            
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ {input_file}: {e}")
        # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
        with open(output_file, 'w') as f:
            f.write("")

def download_sample_dataset():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –Ω–µ–±–æ–ª—å—à–æ–π –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("üì• –°–∫–∞—á–∏–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
    create_sample_dataset()
    
    print("‚úÖ –ü—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –≥–æ—Ç–æ–≤!")
    print("   –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å train_yolo.py")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("üìä –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê –î–õ–Ø YOLOv8")
    print("=" * 60)
    
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç:")
    print("1. –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)")
    print("2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å Kaggle")
    print("3. –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é")
    
    choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-3): ").strip()
    
    if choice == "1":
        download_sample_dataset()
    elif choice == "2":
        kaggle_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Å–∫–∞—á–∞–Ω–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É: ").strip()
        if os.path.exists(kaggle_path):
            convert_kaggle_dataset(kaggle_path)
        else:
            print("‚ùå –ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    elif choice == "3":
        show_download_instructions()
    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä!")

def show_download_instructions():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("\n" + "="*60)
    print("üì• –ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –°–ö–ê–ß–ò–í–ê–ù–ò–Æ –î–ê–¢–ê–°–ï–¢–ê")
    print("="*60)
    
    print("\nüîó –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã:")
    print("1. Car Damage Detection: https://www.kaggle.com/datasets/sshikamaru/car-damage-detection")
    print("2. Vehicle Damage Dataset: https://www.kaggle.com/datasets/ravirajsinh45/real-time-car-detection")
    
    print("\nüìã –ü–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:")
    print("1. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ Kaggle.com")
    print("2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–∞—Ç–∞—Å–µ—Ç–∞")
    print("3. –ù–∞–∂–º–∏—Ç–µ 'Download' (—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è)")
    print("4. –†–∞—Å–ø–∞–∫—É–π—Ç–µ –∞—Ä—Ö–∏–≤ –≤ –ø–∞–ø–∫—É 'downloaded_dataset/'")
    print("5. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python prepare_dataset.py")
    print("6. –í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç 2 –∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É")
    
    print("\n‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç:")
    print("1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python prepare_dataset.py")
    print("2. –í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç 1 (—Å–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä)")
    print("3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python train_yolo.py")

if __name__ == "__main__":
    main()
